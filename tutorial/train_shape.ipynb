{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "train_shape.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GI9KZ3F8TLSK"
      },
      "source": [
        "# EfficientDet Training On A Custom Dataset\n",
        "\n",
        "\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/blob/master/tutorial/train_shape.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/zylo117/Yet-Another-EfficientDet-Pytorch/blob/master/tutorial/train_shape.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "</td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "67-3S5_VTLSL"
      },
      "source": [
        "## This tutorial will show you how to train a custom dataset.\n",
        "\n",
        "## For the sake of simplicity, I generated a dataset of different shapes, like rectangles, triangles, circles.\n",
        "\n",
        "## Please enable GPU support to accelerate on notebook setting if you are using colab.\n",
        "\n",
        "### 0. Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "90laRz20TLSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1680028-17a6-4533-c449-dec8b4436fbc"
      },
      "source": [
        "!pip install numpy==1.21.6 torch==1.12.1 torchvision==0.13.1 opencv-python==4.5.4.60\n",
        "!pip install pycocotools numpy==1.21.6 opencv-python==4.5.4 tqdm tensorboard tensorboardX pyyaml webcolors matplotlib\n",
        "!pip install torch==1.12.1 torchvision==0.13.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.21.6\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n",
            "Collecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting opencv-python==4.5.4.60\n",
            "  Downloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2024.12.14)\n",
            "Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, numpy, torchvision, opencv-python\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.21.6 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.21.6 which is incompatible.\n",
            "arviz 0.20.0 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "astropy 6.1.7 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "bigframes 1.29.0 requires numpy>=1.24.0, but you have numpy 1.21.6 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.21.6 which is incompatible.\n",
            "contourpy 1.3.1 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "flax 0.8.5 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "geopandas 1.0.1 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.21.6 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "langchain 0.3.12 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 1.21.6 which is incompatible.\n",
            "mizani 0.13.1 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "nibabel 5.3.2 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "numexpr 2.10.2 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n",
            "nx-cugraph-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "pandas 2.2.2 requires numpy>=1.22.4; python_version < \"3.11\", but you have numpy 1.21.6 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "peft 0.14.0 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "plotnine 0.14.4 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\n",
            "pylibraft-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.21.6 which is incompatible.\n",
            "rmm-cu12 24.10.0 requires numpy<3.0a0,>=1.23, but you have numpy 1.21.6 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 1.21.6 which is incompatible.\n",
            "statsmodels 0.14.4 requires numpy<3,>=1.22.3, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.21.6 which is incompatible.\n",
            "tensorstore 0.1.71 requires numpy>=1.22.0, but you have numpy 1.21.6 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.12.1 which is incompatible.\n",
            "xarray 2024.11.0 requires numpy>=1.24, but you have numpy 1.21.6 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires numpy>=1.23, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.21.6 opencv-python-4.5.4.60 torch-1.12.1 torchvision-0.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "432a595c43244129990a27fd983eca5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.10/dist-packages (1.21.6)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.5.4 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.5.4\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: torchvision==0.13.1 in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z1yE19SCyLs",
        "outputId": "77f672a9-034f-456e-8fdc-fd003d5a60ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-R5C4DaETLSS"
      },
      "source": [
        "### 1. Prepare Custom Dataset/Pretrained Weights + YOLO to json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def organize_dataset(image_src_dir, label_src_dir, dest_dir):\n",
        "    \"\"\"\n",
        "    이미지와 라벨 파일을 지정된 경로로 복사 및 정리하는 함수.\n",
        "\n",
        "    Args:\n",
        "        image_src_dir (str): 원본 이미지 파일이 위치한 디렉토리 경로.\n",
        "        label_src_dir (str): 원본 라벨 파일이 위치한 디렉토리 경로.\n",
        "        dest_dir (str): 데이터셋을 정리할 최종 경로.\n",
        "\n",
        "    \"\"\"\n",
        "    # 대상 디렉토리 생성\n",
        "    image_dest_dir = os.path.join(dest_dir, \"images\")\n",
        "    label_dest_dir = os.path.join(dest_dir, \"labels\")\n",
        "    os.makedirs(image_dest_dir, exist_ok=True)\n",
        "    os.makedirs(label_dest_dir, exist_ok=True)\n",
        "\n",
        "    # 이미지 파일 복사\n",
        "    for file_name in os.listdir(image_src_dir):\n",
        "        if file_name.endswith((\".jpg\", \".png\", \".jpeg\")):  # 이미지 확장자 확인\n",
        "            src_path = os.path.join(image_src_dir, file_name)\n",
        "            dest_path = os.path.join(image_dest_dir, file_name)\n",
        "            shutil.copy(src_path, dest_path)\n",
        "            print(f\"이미지 복사: {src_path} → {dest_path}\")\n",
        "\n",
        "    # 라벨 파일 복사\n",
        "    for file_name in os.listdir(label_src_dir):\n",
        "        if file_name.endswith(\".txt\"):  # 라벨 파일 확장자 확인\n",
        "            src_path = os.path.join(label_src_dir, file_name)\n",
        "            dest_path = os.path.join(label_dest_dir, file_name)\n",
        "            shutil.copy(src_path, dest_path)\n",
        "            print(f\"라벨 복사: {src_path} → {dest_path}\")\n",
        "\n",
        "    print(\"\\n데이터셋 정리가 완료되었습니다!\")\n",
        "    print(f\"이미지 경로: {image_dest_dir}\")\n",
        "    print(f\"라벨 경로: {label_dest_dir}\")\n",
        "\n",
        "# 사용 예시\n",
        "image_src_dir = \"/content/drive/MyDrive/datasets/augmented_train/images\"  # 이미지가 있는 원본 디렉토리\n",
        "label_src_dir = \"/content/drive/MyDrive/datasets/augmented_train/labels\"  # 라벨이 있는 원본 디렉토리\n",
        "dest_dir = \"/content/drive/MyDrive/dataset/train\"  # 데이터를 정리할 최종 디렉토리\n",
        "\n",
        "organize_dataset(image_src_dir, label_src_dir, dest_dir)"
      ],
      "metadata": {
        "id": "18tnsuuZDu0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JmCQj3rhTLSS"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "def yolo_to_coco(yolo_dir, save_path, class_names):\n",
        "    \"\"\"\n",
        "    YOLO 형식 데이터를 COCO 형식 JSON으로 변환\n",
        "    Args:\n",
        "        yolo_dir (str): YOLO 데이터 디렉토리 (images와 labels 디렉토리가 포함된 상위 디렉토리).\n",
        "        save_path (str): 변환된 COCO JSON 파일을 저장할 경로.\n",
        "        class_names (list): 클래스 이름 리스트. 예: ['class1', 'class2', ...].\n",
        "    \"\"\"\n",
        "    print(\"YOLO → COCO 변환 시작...\")\n",
        "\n",
        "    images = []\n",
        "    annotations = []\n",
        "    categories = []\n",
        "\n",
        "    # 클래스 정보 추가\n",
        "    print(\"카테고리 추가 중...\")\n",
        "    for idx, class_name in enumerate(class_names):\n",
        "        categories.append({\n",
        "            \"id\": idx + 1,\n",
        "            \"name\": class_name\n",
        "        })\n",
        "    print(f\"카테고리 등록 완료: {categories}\")\n",
        "\n",
        "    annotation_id = 1  # 각 객체의 고유 ID\n",
        "    label_dir = os.path.join(yolo_dir, \"labels\")\n",
        "    image_dir = os.path.join(yolo_dir, \"images\")\n",
        "\n",
        "    print(\"라벨 디렉토리:\", label_dir)\n",
        "    print(\"이미지 디렉토리:\", image_dir)\n",
        "\n",
        "    # 이미지 및 라벨 파일 읽기\n",
        "    for label_file in os.listdir(label_dir):\n",
        "        if not label_file.endswith(\".txt\"):\n",
        "            continue\n",
        "\n",
        "        print(f\"처리 중인 라벨 파일: {label_file}\")\n",
        "\n",
        "        # 이미지 파일과 라벨 파일 매칭\n",
        "        image_id = len(images) + 1\n",
        "        image_name = label_file.replace(\".txt\", \".jpg\")\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"[경고] 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                width, height = img.size\n",
        "        except Exception as e:\n",
        "            print(f\"[오류] 이미지 파일을 열 수 없습니다: {image_path}, 오류: {e}\")\n",
        "            continue\n",
        "\n",
        "        images.append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": image_name,\n",
        "            \"width\": width,\n",
        "            \"height\": height\n",
        "        })\n",
        "\n",
        "        print(f\"이미지 추가 완료: {image_name} (ID: {image_id})\")\n",
        "\n",
        "        # 라벨 파일 읽기\n",
        "        with open(os.path.join(label_dir, label_file), \"r\") as f:\n",
        "            for line in f.readlines():\n",
        "                parts = line.strip().split()\n",
        "                class_id = int(parts[0])\n",
        "                x_center = float(parts[1])\n",
        "                y_center = float(parts[2])\n",
        "                box_width = float(parts[3])\n",
        "                box_height = float(parts[4])\n",
        "\n",
        "                x_min = (x_center - box_width / 2) * width\n",
        "                y_min = (y_center - box_height / 2) * height\n",
        "                bbox_width = box_width * width\n",
        "                bbox_height = box_height * height\n",
        "\n",
        "                annotations.append({\n",
        "                    \"id\": annotation_id,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"category_id\": class_id + 1,\n",
        "                    \"bbox\": [x_min, y_min, bbox_width, bbox_height],\n",
        "                    \"area\": bbox_width * bbox_height,\n",
        "                    \"iscrowd\": 0\n",
        "                })\n",
        "                print(f\"   -> 바운딩 박스 추가: {annotations[-1]}\")\n",
        "                annotation_id += 1\n",
        "\n",
        "    # COCO JSON 구조\n",
        "    coco_format = {\n",
        "        \"images\": images,\n",
        "        \"annotations\": annotations,\n",
        "        \"categories\": categories\n",
        "    }\n",
        "\n",
        "    # JSON 파일 저장 전에 디렉토리 생성\n",
        "    save_dir = os.path.dirname(save_path)\n",
        "    os.makedirs(save_dir, exist_ok=True)  # 디렉토리가 없으면 생성\n",
        "\n",
        "    # JSON 파일 저장\n",
        "    try:\n",
        "        with open(save_path, \"w\") as json_file:\n",
        "            json.dump(coco_format, json_file, indent=4)\n",
        "        print(f\"COCO JSON 파일이 {save_path}에 저장되었습니다.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[오류] JSON 파일 저장 실패: {e}\")\n",
        "\n",
        "# 사용 예시\n",
        "yolo_dir = \"/content/drive/MyDrive/EfficientDet/dataset/val\"  # YOLO 데이터 디렉토리 경로\n",
        "save_path = \"/content/drive/MyDrive/annotations/val_annotations.json\"  # 저장할 JSON 경로\n",
        "class_names = [\"nameplate_working\", \"insignia_working\", \"rankbadge_working\"]  # 클래스 이름 리스트\n",
        "\n",
        "# 실행\n",
        "yolo_to_coco(yolo_dir, save_path, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_files(src_dir, dest_dir, file_extensions=None):\n",
        "    \"\"\"\n",
        "    특정 디렉토리의 파일을 다른 디렉토리로 복사\n",
        "    Args:\n",
        "        src_dir (str): 원본 디렉토리 경로\n",
        "        dest_dir (str): 복사할 대상 디렉토리 경로\n",
        "        file_extensions (list, optional): 복사할 파일 확장자 리스트. None이면 모든 파일 복사.\n",
        "    \"\"\"\n",
        "    # 대상 디렉토리 생성\n",
        "    os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "    # 원본 디렉토리의 파일 복사\n",
        "    for file_name in os.listdir(src_dir):\n",
        "        # 파일 확장자 필터링\n",
        "        if file_extensions:\n",
        "            if not file_name.lower().endswith(tuple(file_extensions)):\n",
        "                continue\n",
        "\n",
        "        # 파일 복사\n",
        "        src_file = os.path.join(src_dir, file_name)\n",
        "        dest_file = os.path.join(dest_dir, file_name)\n",
        "\n",
        "        if os.path.isfile(src_file):  # 파일만 복사\n",
        "            shutil.copy(src_file, dest_file)\n",
        "            print(f\"복사 완료: {src_file} → {dest_file}\")\n",
        "\n",
        "# 사용 예제\n",
        "src_directory = \"/content/drive/MyDrive/EfficientDet/dataset/val/images\"  # 복사할 원본 디렉토리 경로\n",
        "dest_directory = \"/content/drive/MyDrive/datasets/shape/images/val\"  # 복사할 대상 디렉토리 경로\n",
        "file_exts = [\".jpg\", \".png\", \".txt\"]  # 복사할 파일 확장자 (예: 이미지와 텍스트 파일)\n",
        "\n",
        "copy_files(src_directory, dest_directory, file_exts)"
      ],
      "metadata": {
        "id": "8UpkUbaXaAmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. 프로젝트 클론 및 설정\n",
        "if \"projects\" not in os.getcwd():\n",
        "    !git clone --depth 1 https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch\n",
        "    os.chdir('Yet-Another-EfficientDet-Pytorch')\n",
        "    sys.path.append('.')\n",
        "else:\n",
        "    !git pull\n",
        "\n",
        "# 2. 데이터셋 디렉토리 설정 (사용자 데이터셋 사용)\n",
        "# Google Drive 경로에 데이터셋 디렉토리를 생성\n",
        "dataset_dir = \"/content/drive/MyDrive/datasets/shape\"\n",
        "os.makedirs(os.path.join(dataset_dir, \"images/train\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_dir, \"images/val\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(dataset_dir, \"annotations\"), exist_ok=True)\n",
        "\n",
        "# 3. 가중치 디렉토리 생성 및 다운로드\n",
        "weights_dir = \"weights\"\n",
        "os.makedirs(weights_dir, exist_ok=True)\n",
        "if not os.path.exists(os.path.join(weights_dir, \"efficientdet-d0.pth\")):\n",
        "    !wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth -O weights/efficientdet-d0.pth\n",
        "\n",
        "# 4. 데이터셋 디렉토리 및 가중치 파일 확인\n",
        "print(\"데이터셋 디렉토리 구조 확인:\")\n",
        "!ls -R /content/drive/MyDrive/datasets/shape\n",
        "print(\"\\n가중치 파일 확인:\")\n",
        "!ls weights"
      ],
      "metadata": {
        "id": "y1ZA5byETeT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p datasets/shape/annotations\n",
        "!cp /content/drive/MyDrive/datasets/shape/annotations/instances_train.json datasets/shape/annotations/instances_train.json\n",
        "!cp /content/drive/MyDrive/datasets/shape/annotations/instances_val.json datasets/shape/annotations/instances_val.json\n",
        "!ls datasets/shape/annotations/"
      ],
      "metadata": {
        "id": "xlBlaK4hpYHA",
        "outputId": "65f23a64-a919-4899-957e-e5785bcde588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instances_train.json  instances_val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7Q2onXNZTLSV"
      },
      "source": [
        "### 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile projects/shape.yml\n",
        "project_name: shape\n",
        "train_set: train\n",
        "val_set: val\n",
        "num_gpus: 1\n",
        "\n",
        "mean: [0.485, 0.456, 0.406]\n",
        "std: [0.229, 0.224, 0.225]\n",
        "\n",
        "obj_list: ['nameplate_working', 'insignia_working', 'rankbadge_working']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1wNCSshXHpo",
        "outputId": "f353748e-db62-437f-ef73-7d5276cc61d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting projects/shape.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MD8rOS9WKri",
        "outputId": "34c11132-e8e0-475e-d9b5-e6ad656adc3b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name \"train.py\""
      ],
      "metadata": {
        "id": "nF7o3Iu9sJyD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a-eznEu5TLSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa8e47d-e00d-4fd1-c7a0-63b89e5616a5"
      },
      "source": [
        "# consider this is a simple dataset, train head will be enough.\n",
        "! python train.py -c 0 -p shape --head_only True --lr 1e-3 --batch_size 32 --load_weights weights/efficientdet-d0.pth  --num_epochs 50 --save_interval 100\n",
        "\n",
        "# the loss will be high at first\n",
        "# don't panic, be patient,\n",
        "# just wait for a little bit longer"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.25s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Yet-Another-EfficientDet-Pytorch/train.py\", line 326, in <module>\n",
            "    train(opt)\n",
            "  File \"/content/Yet-Another-EfficientDet-Pytorch/train.py\", line 125, in train\n",
            "    ratios=eval(params.anchors_ratios), scales=eval(params.anchors_scales))\n",
            "TypeError: eval() arg 1 must be a string, bytes or code object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOTfo4exsH9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v3cf0BwZl-ut"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "05mjrGRETLSZ"
      },
      "source": [
        "### 3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9yzNyaSxTLSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "f38ef0e7-bf30-428a-cf93-43e43a60fdae"
      },
      "source": [
        "#get latest weight file\n",
        "%cd logs/shape\n",
        "weight_file = !ls -Art | grep efficientdet\n",
        "%cd ../..\n",
        "\n",
        "#uncomment the next line to specify a weight file\n",
        "#weight_file[-1] = 'efficientdet-d0_49_1400.pth'\n",
        "\n",
        "! python coco_eval.py -c 0 -p shape -w \"logs/shape/{weight_file[-1]}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running coco-style evaluation on project shape, weights logs/shape/efficientdet-d0_49_1400.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 100/100 [00:08<00:00, 11.80it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.63s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.46s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.781\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.947\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.868\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.794\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.470\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.841\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.843\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.850\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zhV3bNF3TLSc"
      },
      "source": [
        "### 4. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uEDHMAIJTLSc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "cbeedcbd-cd4f-41a6-e0d6-875398081cd8"
      },
      "source": [
        "import torch\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from backbone import EfficientDetBackbone\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
        "from utils.utils import preprocess, invert_affine, postprocess\n",
        "\n",
        "compound_coef = 0\n",
        "force_input_size = None  # set None to use default size\n",
        "img_path = 'datasets/shape/val/999.jpg'\n",
        "\n",
        "threshold = 0.2\n",
        "iou_threshold = 0.2\n",
        "\n",
        "use_cuda = True\n",
        "use_float16 = False\n",
        "cudnn.fastest = True\n",
        "cudnn.benchmark = True\n",
        "\n",
        "obj_list = ['rectangle', 'circle']\n",
        "\n",
        "# tf bilinear interpolation is different from any other's, just make do\n",
        "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
        "input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
        "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
        "\n",
        "if use_cuda:\n",
        "    x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
        "else:\n",
        "    x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
        "\n",
        "x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
        "\n",
        "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
        "\n",
        "                             # replace this part with your project's anchor config\n",
        "                             ratios=[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)],\n",
        "                             scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
        "\n",
        "model.load_state_dict(torch.load('logs/shape/'+weight_file[-1]))\n",
        "model.requires_grad_(False)\n",
        "model.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "if use_float16:\n",
        "    model = model.half()\n",
        "\n",
        "with torch.no_grad():\n",
        "    features, regression, classification, anchors = model(x)\n",
        "\n",
        "    regressBoxes = BBoxTransform()\n",
        "    clipBoxes = ClipBoxes()\n",
        "\n",
        "    out = postprocess(x,\n",
        "                      anchors, regression, classification,\n",
        "                      regressBoxes, clipBoxes,\n",
        "                      threshold, iou_threshold)\n",
        "\n",
        "out = invert_affine(framed_metas, out)\n",
        "\n",
        "for i in range(len(ori_imgs)):\n",
        "    if len(out[i]['rois']) == 0:\n",
        "        continue\n",
        "    ori_imgs[i] = ori_imgs[i].copy()\n",
        "    for j in range(len(out[i]['rois'])):\n",
        "        (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
        "        cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "        obj = obj_list[out[i]['class_ids'][j]]\n",
        "        score = float(out[i]['scores'][j])\n",
        "\n",
        "        cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
        "                    (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                    (255, 255, 0), 1)\n",
        "\n",
        "        plt.imshow(ori_imgs[i])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}